{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b8edc00-a2c2-476c-b8a1-caaed1c17f0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier, VotingClassifier, StackingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ee4d1e1-14d0-4b40-adf2-ed01418543c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "da2fe9b9-1c5c-409e-9b07-6053e353f06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Gradient Boosting\n",
      "Accuracy (CV): 0.8013\n",
      "Precisión (CV): 0.8375\n",
      "Recall (CV): 0.8187\n",
      "F1 Score (CV): 0.8213\n",
      "Matriz de Confusión:\n",
      "[[24  5]\n",
      " [ 7 25]]\n",
      "==============================\n",
      "Modelo: Random Forest\n",
      "Accuracy (CV): 0.8178\n",
      "Precisión (CV): 0.8257\n",
      "Recall (CV): 0.8940\n",
      "F1 Score (CV): 0.8387\n",
      "Matriz de Confusión:\n",
      "[[24  5]\n",
      " [ 4 28]]\n",
      "==============================\n",
      "Modelo: Bagging\n",
      "Accuracy (CV): 0.8055\n",
      "Precisión (CV): 0.8172\n",
      "Recall (CV): 0.8269\n",
      "F1 Score (CV): 0.8285\n",
      "Matriz de Confusión:\n",
      "[[24  5]\n",
      " [ 3 29]]\n",
      "==============================\n",
      "Modelo: Voting\n",
      "Accuracy (CV): 0.7815\n",
      "Precisión (CV): 0.8094\n",
      "Recall (CV): 0.7978\n",
      "F1 Score (CV): 0.7989\n",
      "Matriz de Confusión:\n",
      "[[26  3]\n",
      " [ 5 27]]\n",
      "==============================\n",
      "Modelo: Stacking\n",
      "Accuracy (CV): 0.8018\n",
      "Precisión (CV): 0.8080\n",
      "Recall (CV): 0.8423\n",
      "F1 Score (CV): 0.8222\n",
      "Matriz de Confusión:\n",
      "[[25  4]\n",
      " [ 4 28]]\n",
      "==============================\n",
      "Modelo: AdaBoost\n",
      "Accuracy (CV): 0.8137\n",
      "Precisión (CV): 0.8348\n",
      "Recall (CV): 0.8258\n",
      "F1 Score (CV): 0.8282\n",
      "Matriz de Confusión:\n",
      "[[26  3]\n",
      " [ 8 24]]\n",
      "==============================\n",
      "Promedio de Accuracy: 0.8036\n",
      "Promedio de Precisión: 0.8221\n",
      "Promedio de Recall: 0.8342\n",
      "Promedio de F1 Score: 0.8230\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario de modelos\n",
    "models = {\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=110, max_depth=3, warm_start=True ),\n",
    "    \"Random Forest\": RandomForestClassifier(criterion='entropy', n_estimators=60, max_depth=3, bootstrap=True),\n",
    "    \"Bagging\": BaggingClassifier(\n",
    "        n_estimators= 100,max_samples=0.5, warm_start=True),\n",
    "    \"Voting\": VotingClassifier(estimators=[\n",
    "        ('knn', KNeighborsClassifier(weights='uniform')),\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('svc', SVC(probability=True)),\n",
    "        ('nb', GaussianNB())\n",
    "    ]),\n",
    "    \"Stacking\": StackingClassifier(estimators=[\n",
    "        ('knn', KNeighborsClassifier()),\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('svc', SVC(probability=True)),\n",
    "        ('nb', GaussianNB())\n",
    "    ], final_estimator=LogisticRegression()),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME')\n",
    "}\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Listas para almacenar las métricas\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterar sobre los modelos\n",
    "for name, model in models.items():\n",
    "    # Realizar validación cruzada\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    accuracy = cv_scores.mean()\n",
    "    precision = cross_val_score(model, X_train, y_train, cv=10, scoring='precision').mean()\n",
    "    recall = cross_val_score(model, X_train, y_train, cv=10, scoring='recall').mean()\n",
    "    f1 = cross_val_score(model, X_train, y_train, cv=10, scoring='f1').mean()\n",
    "    \n",
    "    # Ajustar el modelo al conjunto de entrenamiento completo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Agregar las métricas a las listas\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"Modelo: {name}\")\n",
    "    print(f\"Accuracy (CV): {accuracy:.4f}\")\n",
    "    print(f\"Precisión (CV): {precision:.4f}\")\n",
    "    print(f\"Recall (CV): {recall:.4f}\")\n",
    "    print(f\"F1 Score (CV): {f1:.4f}\")\n",
    "    print(f\"Matriz de Confusión:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"=\"*30)\n",
    "\n",
    "# Imprimir promedios\n",
    "print(f\"Promedio de Accuracy: {sum(accuracy_scores)/len(accuracy_scores):.4f}\")\n",
    "print(f\"Promedio de Precisión: {sum(precision_scores)/len(precision_scores):.4f}\")\n",
    "print(f\"Promedio de Recall: {sum(recall_scores)/len(recall_scores):.4f}\")\n",
    "print(f\"Promedio de F1 Score: {sum(f1_scores)/len(f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d64d2d-115c-4beb-925b-2344eb8e6778",
   "metadata": {
    "tags": []
   },
   "source": [
    "En la siguiente tabla podemos observar como se desempeñaron los algoritmos. Estos datos es ya habiendo probado varios parametros distintos. \n",
    "\n",
    "Modelo            | Accuracy | Precisión | Recall  | F1 Score \n",
    "-------------------|----------|-----------|---------|----------\n",
    "Gradient Boosting | 0.8095   | 0.8323    | 0.8187  | 0.8174   \n",
    "Random Forest     | 0.8178   | 0.8257    | 0.8940  | 0.8387   \n",
    "Bagging           | 0.8055   | 0.8172    | 0.8269  | 0.8285   \n",
    "Voting            | 0.7815   | 0.8094    | 0.7978  | 0.7989   \n",
    "Stacking          | 0.8018   | 0.8080    | 0.8423  | 0.8222   \n",
    "AdaBoost          | 0.8137   | 0.8348    | 0.8258  | 0.8282   \n",
    "\n",
    "Es notorio que los algoritmos sufren un poco, especialmente voting que tiene unas metricas muy pobres. Se probo realizar un PCA antes pero eso empeoro los resultados por lo que se opto por probar ganancia de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d7d5f2d3-640a-435f-a1e9-120ca0334401",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Gradient Boosting\n",
      "Accuracy: 0.8033\n",
      "Precisión: 0.7941\n",
      "Recall: 0.8438\n",
      "F1 Score: 0.8182\n",
      "Matriz de Confusión:\n",
      "[[22  7]\n",
      " [ 5 27]]\n",
      "==============================\n",
      "Modelo: Random Forest\n",
      "Accuracy: 0.8525\n",
      "Precisión: 0.8710\n",
      "Recall: 0.8438\n",
      "F1 Score: 0.8571\n",
      "Matriz de Confusión:\n",
      "[[25  4]\n",
      " [ 5 27]]\n",
      "==============================\n",
      "Modelo: Bagging\n",
      "Accuracy: 0.8525\n",
      "Precisión: 0.8485\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.8615\n",
      "Matriz de Confusión:\n",
      "[[24  5]\n",
      " [ 4 28]]\n",
      "==============================\n",
      "Modelo: Voting\n",
      "Accuracy: 0.8689\n",
      "Precisión: 0.8750\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.8750\n",
      "Matriz de Confusión:\n",
      "[[25  4]\n",
      " [ 4 28]]\n",
      "==============================\n",
      "Modelo: Stacking\n",
      "Accuracy: 0.8852\n",
      "Precisión: 0.8788\n",
      "Recall: 0.9062\n",
      "F1 Score: 0.8923\n",
      "Matriz de Confusión:\n",
      "[[25  4]\n",
      " [ 3 29]]\n",
      "==============================\n",
      "Modelo: AdaBoost\n",
      "Accuracy: 0.8525\n",
      "Precisión: 0.8966\n",
      "Recall: 0.8125\n",
      "F1 Score: 0.8525\n",
      "Matriz de Confusión:\n",
      "[[26  3]\n",
      " [ 6 26]]\n",
      "==============================\n",
      "Promedio de Accuracy: 0.8525\n",
      "Promedio de Precisión: 0.8607\n",
      "Promedio de Recall: 0.8594\n",
      "Promedio de F1 Score: 0.8594\n"
     ]
    }
   ],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calcular la ganancia de información\n",
    "info_gains = mutual_info_classif(X_train, y_train)\n",
    "\n",
    "# Definir un umbral para la selección de características\n",
    "umbral = 0.1\n",
    "caracteristicas_seleccionadas = X_train.columns[info_gains > umbral]\n",
    "X_train_seleccionado = X_train[caracteristicas_seleccionadas]\n",
    "X_test_seleccionado = X_test[caracteristicas_seleccionadas]\n",
    "\n",
    "# Crear un diccionario de modelos\n",
    "models = {\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=110, max_depth=3, warm_start=True),\n",
    "    \"Random Forest\": RandomForestClassifier(criterion='entropy', n_estimators=60, max_depth=3, bootstrap=True),\n",
    "    \"Bagging\": BaggingClassifier(n_estimators=100, max_samples=0.5, warm_start=True),\n",
    "    \"Voting\": VotingClassifier(estimators=[\n",
    "        ('knn', KNeighborsClassifier(weights='uniform')),\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('svc', SVC(probability=True)),\n",
    "        ('nb', GaussianNB())\n",
    "    ]),\n",
    "    \"Stacking\": StackingClassifier(estimators=[\n",
    "        ('knn', KNeighborsClassifier()),\n",
    "        ('logreg', LogisticRegression()),\n",
    "        ('svc', SVC(probability=True)),\n",
    "        ('nb', GaussianNB())\n",
    "    ], final_estimator=LogisticRegression()),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME')\n",
    "}\n",
    "\n",
    "# Listas para almacenar las métricas\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterar sobre los modelos\n",
    "for name, model in models.items():\n",
    "    # Entrenar el modelo con características seleccionadas\n",
    "    model.fit(X_train_seleccionado, y_train)\n",
    "    \n",
    "    # Predecir en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test_seleccionado)\n",
    "    \n",
    "    # Calcular las métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Agregar las métricas a las listas\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"Modelo: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precisión: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Matriz de Confusión:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"=\"*30)\n",
    "\n",
    "# Imprimir promedios\n",
    "print(f\"Promedio de Accuracy: {sum(accuracy_scores)/len(accuracy_scores):.4f}\")\n",
    "print(f\"Promedio de Precisión: {sum(precision_scores)/len(precision_scores):.4f}\")\n",
    "print(f\"Promedio de Recall: {sum(recall_scores)/len(recall_scores):.4f}\")\n",
    "print(f\"Promedio de F1 Score: {sum(f1_scores)/len(f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625ed083-96c1-4c1f-802d-25a122266243",
   "metadata": {},
   "source": [
    "Podemos ver que las metricas aumentaron mejoraron bastante en especial stacking y voting que son los dos mejores modelos en cuanto a su balance. \n",
    "\n",
    "Modelo            | Accuracy | Precisión | Recall  | F1 Score \n",
    "-------------------|----------|-----------|---------|----------\n",
    "Gradient Boosting | 0.8033   | 0.7941    | 0.8438  | 0.8182   \n",
    "Random Forest     | 0.8525   | 0.8710    | 0.8438  | 0.8571   \n",
    "Bagging           | 0.8525   | 0.8485    | 0.8750  | 0.8615   \n",
    "Voting            | 0.8689   | 0.8750    | 0.8750  | 0.8750   \n",
    "Stacking          | 0.8852   | 0.8788    | 0.9062  | 0.8923   \n",
    "AdaBoost          | 0.8525   | 0.8966    | 0.8125  | 0.8525   \n",
    "\n",
    "Conluyendo, podemos decir que los dos mejores modelos tienen parametros competitivos superando a los modelos de la practica pasada. Esto no quiere decir que sean mejores  dado que anteriormente no se utilizo information gain por lo que no seria una comparativa justa. \n",
    "Aunque los modelos son relativamente buenos, no son capaces de superar el umbral de las metricas en mas de 90 por lo que podria decirse que les falta mas refinamiento para este caso especifico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89541e3-72e1-41b0-bf5e-489b3ef3f8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
